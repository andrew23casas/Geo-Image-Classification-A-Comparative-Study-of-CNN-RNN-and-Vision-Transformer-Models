{"cells":[{"cell_type":"code","source":["!gdown --id 1zre8_TMtUeHZkQKcOTTueNcAqY_aXJFU\n","!mkdir training\n","!tar -xzf resized_dataset.tar.gz -C training"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8SKFwMouJZ7","executionInfo":{"status":"ok","timestamp":1681944833166,"user_tz":240,"elapsed":19752,"user":{"displayName":"Rune Myrskog","userId":"09479974809947825610"}},"outputId":"2a4e1531-7586-41f4-b130-b1028e073859"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.9/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1zre8_TMtUeHZkQKcOTTueNcAqY_aXJFU\n","To: /content/resized_dataset.tar.gz\n","100% 274M/274M [00:03<00:00, 77.1MB/s]\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zEghZ3XRe-fp","executionInfo":{"status":"ok","timestamp":1681944840283,"user_tz":240,"elapsed":128,"user":{"displayName":"Rune Myrskog","userId":"09479974809947825610"}}},"outputs":[],"source":["# change num_countries to the number you want (maximum is 19)\n","num_countries = 19\n","\n","# dictionaries to be populated with pairing from numbers to the label they correspond to i.e 0: \"Canada\", 1: \"Russia\", etc.\n","label_to_index = {}\n","index_to_label = {}"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4455,"status":"ok","timestamp":1681944898209,"user":{"displayName":"Rune Myrskog","userId":"09479974809947825610"},"user_tz":240},"id":"kUaK7dG1lrjd","outputId":"00e5de19-295f-4e05-b286-8d950415aa56"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading 1500 images from Australia\n","loading 944 images from Thailand\n","loading 1500 images from France\n","loading 726 images from Sweden\n","loading 1500 images from Brazil\n","loading 863 images from Poland\n","loading 901 images from Mexico\n","loading 689 images from Argentina\n","loading 698 images from Germany\n","loading 1183 images from South Africa\n","loading 1500 images from Japan\n","loading 1500 images from Russia\n","loading 1049 images from Finland\n","loading 789 images from Italy\n","loading 1500 images from United States\n","loading 707 images from Singapore\n","loading 1500 images from United Kingdom\n","loading 1382 images from Canada\n","loading 1075 images from Spain\n","loading 500 images from Australia\n","loading 500 images from Thailand\n","loading 500 images from France\n","loading 500 images from Sweden\n","loading 500 images from Brazil\n","loading 500 images from Poland\n","loading 500 images from Mexico\n","loading 500 images from Argentina\n","loading 500 images from Germany\n","loading 500 images from South Africa\n","loading 500 images from Japan\n","loading 500 images from Russia\n","loading 500 images from Finland\n","loading 500 images from Italy\n","loading 500 images from United States\n","loading 500 images from Singapore\n","loading 500 images from United Kingdom\n","loading 500 images from Canada\n","loading 500 images from Spain\n"]}],"source":["#load in dataset\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","base_dir = '/content/training'\n","\n","import os\n","import glob\n","from PIL import Image\n","from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","\n","# Function to load images and labels from your folder structure\n","def load_images_and_labels(base_dir, num_countries, max_per_country = 1500):\n","    images = []\n","    labels = []\n","    \n","    # get all the folders from the base directory or small subset if use_small is true\n","    folders = os.listdir(base_dir)[:num_countries]\n","\n","\n","    # Iterate over the folders \n","    for index, folder in enumerate(folders):\n","        folder_path = os.path.join(base_dir, folder)\n","        \n","        # Check if it's a directory and has the expected structure\n","        if os.path.isdir(folder_path):\n","            image_files = glob.glob(os.path.join(folder_path, 'canvas_*.jpg'))\n","            print(f\"loading { min(len(image_files), max_per_country) } images from {folder}\")\n","\n","            label = folder\n","            index_to_label[index] = label\n","            label_to_index[label] = index\n","            \n","            # Iterate over the image files inside the folder\n","            for i, image_file in enumerate(image_files):\n","                if i >= max_per_country:\n","                  break\n","\n","                # Read the image using PIL\n","                image = Image.open(image_file)\n","                \n","                # Append the image and label to the corresponding lists\n","                #image = image.resize((256,256)) # already 256x256\n","                images.append(image) \n","                labels.append(label)\n","    \n","    return images, labels\n","\n","images_1500, labels_1500 = load_images_and_labels(base_dir, num_countries, max_per_country=1500)\n","images_500, labels_500 = load_images_and_labels(base_dir, num_countries, max_per_country=500)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8yg-4XT5mZwM"},"outputs":[],"source":["#import libraries\n","import os\n","import glob\n","import numpy as np\n","from PIL import Image\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, GRU, Dense\n","from typing import *\n","from collections import defaultdict\n","from PIL import Image\n","from IPython.display import display\n","from glob import glob\n","import re\n","import os\n","from random import shuffle\n","import time\n","from matplotlib import pyplot as plt\n","from matplotlib.collections import LineCollection\n","import xml.etree.ElementTree as ET\n","import numpy as np\n","from torch.nn import functional as F\n"," \n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import ToTensor\n","from torchvision import transforms, models\n","import torch.optim as optim\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-MVNnsXjAOm_"},"outputs":[],"source":["# wrap the data in Dataset class for ease of use later\n","class ImageDataset(Dataset):\n","  def __init__(self, images, labels, transform=None, target_transform=None):\n","        self.images = images\n","        self.labels = labels\n","        self.transform = transform\n","        self.target_transform = None\n","       \n","\n","  def __len__(self):\n","        return len(self.labels)\n","\n","  def __getitem__(self, idx):\n","        label = self.labels[idx]\n","        image = self.images[idx]\n","\n","        if self.transform:\n","          image = self.transform(image)\n","        if self.target_transform:\n","          label = self.target_transform(label)\n","\n","        return image, label_to_index[label] # convert label to index \n","\n","\n","# need this transform to make images the expected size \n","  \n","transform = transforms.Compose([\n","                    transforms.Resize((224, 224)),\n","                    transforms.ToTensor(),\n","                    ])\n","\n","\n","dataset_1500 = ImageDataset(images_1500, labels_1500, transform=transform)\n","dataset_500 = ImageDataset(images_500, labels_500, transform=transform)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZxLnZQPkKQ4"},"outputs":[],"source":["def make_data_loaders(dataset, batch_size=16, train_frac=0.8):\n","\n","  length = len(dataset)\n","\n","  # remainder of data split equally into test and validation sets\n","  test_frac = (1 - train_frac) / 2\n","\n","  train_len = int(train_frac * length)\n","  test_len = int(test_frac * length)\n","  val_len = length - train_len - test_len\n","\n","  train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_len, val_len, test_len])\n","\n","  train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, prefetch_factor=8)\n","  val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=2, prefetch_factor=8)\n","  test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=2, prefetch_factor=8)\n","  \n","  return train_loader, val_loader, test_loader\n","\n","train_loader_1500, val_loader_1500, test_loader_1500 = make_data_loaders(dataset_1500)\n","train_loader_500, val_loader_500, test_loader_500 = make_data_loaders(dataset_500)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vs9VsmP7U0tW"},"outputs":[],"source":["# Load a pre-trained model (ResNet18)\n","#pretrained_cnn = models.resnet18(pretrained=True)\n","\n","# Remove the fully connected layer from the pre-trained model\n","#pretrained_cnn = nn.Sequential(*list(pretrained_cnn.children())[:-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WnTuQN9GognS"},"outputs":[],"source":["#Create the CNN+RNN model\n","from torchvision.models import mobilenet_v2\n","\n","class CNN_RNN_Model(nn.Module):\n","    def __init__(self, num_classes):\n","        super(CNN_RNN_Model, self).__init__()\n","        self.cnn = mobilenet_v2(pretrained=True).features\n","        self.rnn = nn.GRU(1280, 64, batch_first=True)  # Note the change in input size to 1280\n","        self.fc = nn.Linear(64, num_classes)\n","        \n","    def forward(self, x):\n","        batch_size, c, h, w = x.size()\n","        x = self.cnn(x)\n","        x = F.adaptive_avg_pool2d(x, (1, 1)).view(batch_size, 1, -1)  # Add adaptive average pooling and reshape\n","        _, x = self.rnn(x)\n","        x = self.fc(x.squeeze(1))\n","        return x.view(batch_size, -1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7_c1kKlTpAN4"},"outputs":[],"source":["def get_model(num_classes):\n","    model = CNN_RNN_Model(num_classes=num_classes)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    # Freeze pre-trained layers to prevent updating the weights during training\n","    for param in model.cnn.parameters():\n","        param.requires_grad = False\n","\n","    # Compile the model\n","    model = model.to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(list(model.rnn.parameters()) + list(model.fc.parameters()))\n","\n","    return model, criterion, optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7PSiKIuDpJv8"},"outputs":[],"source":["from torch.cuda.amp import GradScaler, autocast\n","import time\n","import matplotlib.pyplot as plt\n","\n","def train_and_evaluate(train_loader, val_loader, test_loader,num_classes):\n","    num_epochs = 1\n","    accuracies = []\n","    val_accuracies = []\n","    model, criterion, optimizer = get_model(num_classes)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","    scaler = GradScaler()\n","\n","    for epoch in range(num_epochs):\n","        # Training\n","        model.train()\n","        for images, labels in train_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            \n","            with autocast():\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","            \n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","\n","        # Validation\n","        model.eval()\n","        correct = 0\n","        total = 0\n","        batch_count = 0\n","        batch_accuracies = []\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","                batch_accuracy = 100 * correct / total\n","                batch_accuracies.append(batch_accuracy)\n","\n","        val_accuracies.extend(batch_accuracies)\n","        val_accuracy = sum(batch_accuracies) / len(batch_accuracies)\n","        accuracies.append(val_accuracy)\n","\n","            # Testing\n","    test_correct = 0\n","    test_total = 0\n","    test_accuracies = []\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            test_total += labels.size(0)\n","            test_correct += (predicted == labels).sum().item()\n","\n","            test_accuracy = 100 * test_correct / test_total\n","            test_accuracies.append(test_accuracy)\n","    \n","    return val_accuracies, test_accuracies\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["# Modify the function calls to include test_loader\n","val_accuracies_1500, test_accuracies_1500 = train_and_evaluate(train_loader_1500, val_loader_1500, test_loader_1500, num_classes=len(index_to_label))\n","val_accuracies_500, test_accuracies_500 = train_and_evaluate(train_loader_500, val_loader_500, test_loader_500, num_classes=len(index_to_label))\n","\n","\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ge3M0vGTdOMV","executionInfo":{"status":"ok","timestamp":1681939344847,"user_tz":240,"elapsed":2207224,"user":{"displayName":"Andrew Casas","userId":"07701374818979397869"}},"outputId":"df9386e8-a8c1-449c-9ad8-21f1570d9750"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n","100%|██████████| 13.6M/13.6M [00:00<00:00, 157MB/s]\n","/usr/local/lib/python3.9/dist-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n","  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n","/usr/local/lib/python3.9/dist-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n","  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"]}]},{"cell_type":"code","source":["# Plot the test accuracy for each dataset\n","plt.plot(range(len(test_accuracies_1500)), test_accuracies_1500, label=\"Max images = 1500\")\n","plt.plot(range(len(test_accuracies_500)), test_accuracies_500, label=\"Max images = 500\")\n","plt.xlabel(\"Batch\")\n","plt.ylabel(\"Test Accuracy\")\n","plt.title(\"Test Accuracy vs Batch for batch size of 16\")\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242},"id":"iJ0ksM7H3_3g","executionInfo":{"status":"error","timestamp":1681942324343,"user_tz":240,"elapsed":118,"user":{"displayName":"Andrew Casas","userId":"07701374818979397869"}},"outputId":"71312bd7-a3db-418a-b90c-12ffadd70e03"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-d6185d337962>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the test accuracy for each dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplsot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracies_1500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracies_1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Max images = 1500\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracies_500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracies_500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Max images = 500\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'plsot'"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1fKei5ENCIetZ5cO6xFPAFbCPxRalGLLc","timestamp":1681944646987}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}